{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c6abb7a-3e7b-4563-9af4-6edcb4e34fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.7     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.9\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc59154-c8c7-4972-b279-e108ed96d830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for read_delim {readr}\"><tr><td>read_delim {readr}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Read a delimited file (including CSV and TSV) into a tibble</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p><code>read_csv()</code> and <code>read_tsv()</code> are special cases of the more general\n",
       "<code>read_delim()</code>. They're useful for reading the most common types of\n",
       "flat file data, comma separated values and tab separated values,\n",
       "respectively. <code>read_csv2()</code> uses <code style=\"white-space: pre;\">;</code> for the field separator and <code style=\"white-space: pre;\">,</code> for the\n",
       "decimal point. This format is common in some European countries.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "read_delim(\n",
       "  file,\n",
       "  delim = NULL,\n",
       "  quote = \"\\\"\",\n",
       "  escape_backslash = FALSE,\n",
       "  escape_double = TRUE,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  comment = \"\",\n",
       "  trim_ws = FALSE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  progress = show_progress(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_csv(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  progress = show_progress(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_csv2(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  progress = show_progress(),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_tsv(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  progress = show_progress(),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>file</code></td>\n",
       "<td>\n",
       "<p>Either a path to a file, a connection, or literal data\n",
       "(either a single string or a raw vector).\n",
       "</p>\n",
       "<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will\n",
       "be automatically uncompressed. Files starting with <code style=\"white-space: pre;\">http://</code>,\n",
       "<code style=\"white-space: pre;\">https://</code>, <code style=\"white-space: pre;\">ftp://</code>, or <code style=\"white-space: pre;\">ftps://</code> will be automatically\n",
       "downloaded. Remote gz files can also be automatically downloaded and\n",
       "decompressed.\n",
       "</p>\n",
       "<p>Literal data is most useful for examples and tests. To be recognised as\n",
       "literal data, the input must be either wrapped with <code>I()</code>, be a string\n",
       "containing at least one new line, or be a vector containing at least one\n",
       "string with a new line.\n",
       "</p>\n",
       "<p>Using a value of <code>clipboard()</code> will read from the system clipboard.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>delim</code></td>\n",
       "<td>\n",
       "<p>Single character used to separate fields within a record.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>quote</code></td>\n",
       "<td>\n",
       "<p>Single character used to quote strings.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>escape_backslash</code></td>\n",
       "<td>\n",
       "<p>Does the file use backslashes to escape special\n",
       "characters? This is more general than <code>escape_double</code> as backslashes\n",
       "can be used to escape the delimiter character, the quote character, or\n",
       "to add special characters like <code style=\"white-space: pre;\">\\\\n</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>escape_double</code></td>\n",
       "<td>\n",
       "<p>Does the file escape quotes by doubling them?\n",
       "i.e. If this option is <code>TRUE</code>, the value <code style=\"white-space: pre;\">\"\"\"\"</code> represents\n",
       "a single quote, <code style=\"white-space: pre;\">\\\"</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>col_names</code></td>\n",
       "<td>\n",
       "<p>Either <code>TRUE</code>, <code>FALSE</code> or a character vector\n",
       "of column names.\n",
       "</p>\n",
       "<p>If <code>TRUE</code>, the first row of the input will be used as the column\n",
       "names, and will not be included in the data frame. If <code>FALSE</code>, column\n",
       "names will be generated automatically: X1, X2, X3 etc.\n",
       "</p>\n",
       "<p>If <code>col_names</code> is a character vector, the values will be used as the\n",
       "names of the columns, and the first row of the input will be read into\n",
       "the first row of the output data frame.\n",
       "</p>\n",
       "<p>Missing (<code>NA</code>) column names will generate a warning, and be filled\n",
       "in with dummy names <code>...1</code>, <code>...2</code> etc. Duplicate column names\n",
       "will generate a warning and be made unique, see <code>name_repair</code> to control\n",
       "how this is done.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>col_types</code></td>\n",
       "<td>\n",
       "<p>One of <code>NULL</code>, a <code>cols()</code> specification, or\n",
       "a string. See <code>vignette(\"readr\")</code> for more details.\n",
       "</p>\n",
       "<p>If <code>NULL</code>, all column types will be imputed from <code>guess_max</code> rows\n",
       "on the input interspersed throughout the file. This is convenient (and\n",
       "fast), but not robust. If the imputation fails, you'll need to increase\n",
       "the <code>guess_max</code> or supply the correct types yourself.\n",
       "</p>\n",
       "<p>Column specifications created by <code>list()</code> or <code>cols()</code> must contain\n",
       "one column specification for each column. If you only want to read a\n",
       "subset of the columns, use <code>cols_only()</code>.\n",
       "</p>\n",
       "<p>Alternatively, you can use a compact string representation where each\n",
       "character represents one column:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p> c = character\n",
       "</p>\n",
       "</li>\n",
       "<li><p> i = integer\n",
       "</p>\n",
       "</li>\n",
       "<li><p> n = number\n",
       "</p>\n",
       "</li>\n",
       "<li><p> d = double\n",
       "</p>\n",
       "</li>\n",
       "<li><p> l = logical\n",
       "</p>\n",
       "</li>\n",
       "<li><p> f = factor\n",
       "</p>\n",
       "</li>\n",
       "<li><p> D = date\n",
       "</p>\n",
       "</li>\n",
       "<li><p> T = date time\n",
       "</p>\n",
       "</li>\n",
       "<li><p> t = time\n",
       "</p>\n",
       "</li>\n",
       "<li><p> ? = guess\n",
       "</p>\n",
       "</li>\n",
       "<li><p> _ or - = skip\n",
       "</p>\n",
       "<p>By default, reading a file without a column specification will print a\n",
       "message showing what <code>readr</code> guessed they were. To remove this message,\n",
       "set <code>show_col_types = FALSE</code> or set 'options(readr.show_col_types = FALSE).\n",
       "</p>\n",
       "</li></ul>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>col_select</code></td>\n",
       "<td>\n",
       "<p>Columns to include in the results. You can use the same\n",
       "mini-language as <code>dplyr::select()</code> to refer to the columns by name. Use\n",
       "<code>c()</code> or <code>list()</code> to use more than one selection expression. Although this\n",
       "usage is less common, <code>col_select</code> also accepts a numeric column index. See\n",
       "<code>?tidyselect::language</code> for full details on the\n",
       "selection language.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>id</code></td>\n",
       "<td>\n",
       "<p>The name of a column in which to store the file path. This is\n",
       "useful when reading multiple input files and there is data in the file\n",
       "paths, such as the data collection date. If <code>NULL</code> (the default) no extra\n",
       "column is created.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>locale</code></td>\n",
       "<td>\n",
       "<p>The locale controls defaults that vary from place to place.\n",
       "The default locale is US-centric (like R), but you can use\n",
       "<code>locale()</code> to create your own locale that controls things like\n",
       "the default time zone, encoding, decimal mark, big mark, and day/month\n",
       "names.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>na</code></td>\n",
       "<td>\n",
       "<p>Character vector of strings to interpret as missing values. Set this\n",
       "option to <code>character()</code> to indicate no missing values.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>quoted_na</code></td>\n",
       "<td>\n",
       "<p><a href=\"https://lifecycle.r-lib.org/articles/stages.html#deprecated\"><img src=\"../help/figures/lifecycle-deprecated.svg\" alt='[Deprecated]' /></a> Should missing values\n",
       "inside quotes be treated as missing values (the default) or strings. This\n",
       "parameter is soft deprecated as of readr 2.0.0.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>comment</code></td>\n",
       "<td>\n",
       "<p>A string used to identify comments. Any text after the\n",
       "comment characters will be silently ignored.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>trim_ws</code></td>\n",
       "<td>\n",
       "<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from\n",
       "each field before parsing it?</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>skip</code></td>\n",
       "<td>\n",
       "<p>Number of lines to skip before reading data. If <code>comment</code> is\n",
       "supplied any commented lines are ignored <em>after</em> skipping.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>n_max</code></td>\n",
       "<td>\n",
       "<p>Maximum number of lines to read.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>guess_max</code></td>\n",
       "<td>\n",
       "<p>Maximum number of lines to use for guessing column types.\n",
       "See <code>vignette(\"column-types\", package = \"readr\")</code> for more details.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>name_repair</code></td>\n",
       "<td>\n",
       "<p>Handling of column names. The default behaviour is to\n",
       "ensure column names are <code>\"unique\"</code>. Various repair strategies are\n",
       "supported:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>\"minimal\"</code>: No name repair or checks, beyond basic existence of names.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>\"unique\"</code> (default value): Make sure names are unique and not empty.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>\"check_unique\"</code>: no name repair, but check they are <code>unique</code>.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>\"universal\"</code>: Make the names <code>unique</code> and syntactic.\n",
       "</p>\n",
       "</li>\n",
       "<li><p> A function: apply custom name repair (e.g., <code>name_repair = make.names</code>\n",
       "for names in the style of base R).\n",
       "</p>\n",
       "</li>\n",
       "<li><p> A purrr-style anonymous function, see <code>rlang::as_function()</code>.\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>This argument is passed on as <code>repair</code> to <code>vctrs::vec_as_names()</code>.\n",
       "See there for more details on these terms and the strategies used\n",
       "to enforce them.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>num_threads</code></td>\n",
       "<td>\n",
       "<p>The number of processing threads to use for initial\n",
       "parsing and lazy reading of data. If your data contains newlines within\n",
       "fields the parser should automatically detect this and fall back to using\n",
       "one thread only. However if you know your file has newlines within quoted\n",
       "fields it is safest to set <code>num_threads = 1</code> explicitly.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>progress</code></td>\n",
       "<td>\n",
       "<p>Display a progress bar? By default it will only display\n",
       "in an interactive session and not while knitting a document. The automatic\n",
       "progress bar can be disabled by setting option <code>readr.show_progress</code> to\n",
       "<code>FALSE</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>show_col_types</code></td>\n",
       "<td>\n",
       "<p>If <code>FALSE</code>, do not show the guessed column types. If\n",
       "<code>TRUE</code> always show the column types, even if they are supplied. If <code>NULL</code>\n",
       "(the default) only show the column types if they are not explicitly supplied\n",
       "by the <code>col_types</code> argument.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>skip_empty_rows</code></td>\n",
       "<td>\n",
       "<p>Should blank rows be ignored altogether? i.e. If this\n",
       "option is <code>TRUE</code> then blank rows will not be represented at all.  If it is\n",
       "<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>lazy</code></td>\n",
       "<td>\n",
       "<p>Read values lazily? By default the file is initially only\n",
       "indexed and the values are read lazily when accessed. Lazy reading is\n",
       "useful interactively, particularly if you are only interested in a subset\n",
       "of the full dataset. <em>Note</em>, if you later write to the same file you read\n",
       "from you need to set <code>lazy = FALSE</code>. On Windows the file will be locked\n",
       "and on other systems the memory map will become invalid.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>A <code>tibble()</code>. If there are parsing problems, a warning will alert you.\n",
       "You can retrieve the full details by calling <code>problems()</code> on your dataset.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "# Input sources -------------------------------------------------------------\n",
       "# Read from a path\n",
       "read_csv(readr_example(\"mtcars.csv\"))\n",
       "read_csv(readr_example(\"mtcars.csv.zip\"))\n",
       "read_csv(readr_example(\"mtcars.csv.bz2\"))\n",
       "## Not run: \n",
       "# Including remote paths\n",
       "read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n",
       "\n",
       "## End(Not run)\n",
       "\n",
       "# Or directly from a string with `I()`\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"))\n",
       "\n",
       "# Column types --------------------------------------------------------------\n",
       "# By default, readr guesses the columns types, looking at `guess_max` rows.\n",
       "# You can override with a compact specification:\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = \"dc\")\n",
       "\n",
       "# Or with a list of column types:\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = list(col_double(), col_character()))\n",
       "\n",
       "# If there are parsing problems, you get a warning, and can extract\n",
       "# more details with problems()\n",
       "y &lt;- read_csv(I(\"x\\n1\\n2\\nb\"), col_types = list(col_double()))\n",
       "y\n",
       "problems(y)\n",
       "\n",
       "# File types ----------------------------------------------------------------\n",
       "read_csv(I(\"a,b\\n1.0,2.0\"))\n",
       "read_csv2(I(\"a;b\\n1,0;2,0\"))\n",
       "read_tsv(I(\"a\\tb\\n1.0\\t2.0\"))\n",
       "read_delim(I(\"a|b\\n1.0|2.0\"), delim = \"|\")\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>readr</em> version 2.1.2 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{read\\_delim}{Read a delimited file (including CSV and TSV) into a tibble}{read.Rul.delim}\n",
       "\\aliasA{read\\_csv}{read\\_delim}{read.Rul.csv}\n",
       "\\aliasA{read\\_csv2}{read\\_delim}{read.Rul.csv2}\n",
       "\\aliasA{read\\_tsv}{read\\_delim}{read.Rul.tsv}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "\\code{read\\_csv()} and \\code{read\\_tsv()} are special cases of the more general\n",
       "\\code{read\\_delim()}. They're useful for reading the most common types of\n",
       "flat file data, comma separated values and tab separated values,\n",
       "respectively. \\code{read\\_csv2()} uses \\AsIs{;} for the field separator and \\AsIs{,} for the\n",
       "decimal point. This format is common in some European countries.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "read_delim(\n",
       "  file,\n",
       "  delim = NULL,\n",
       "  quote = \"\\\"\",\n",
       "  escape_backslash = FALSE,\n",
       "  escape_double = TRUE,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  comment = \"\",\n",
       "  trim_ws = FALSE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  progress = show_progress(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_csv(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  progress = show_progress(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_csv2(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  progress = show_progress(),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_tsv(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  progress = show_progress(),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{file}] Either a path to a file, a connection, or literal data\n",
       "(either a single string or a raw vector).\n",
       "\n",
       "Files ending in \\code{.gz}, \\code{.bz2}, \\code{.xz}, or \\code{.zip} will\n",
       "be automatically uncompressed. Files starting with \\AsIs{http://},\n",
       "\\AsIs{https://}, \\AsIs{ftp://}, or \\AsIs{ftps://} will be automatically\n",
       "downloaded. Remote gz files can also be automatically downloaded and\n",
       "decompressed.\n",
       "\n",
       "Literal data is most useful for examples and tests. To be recognised as\n",
       "literal data, the input must be either wrapped with \\code{I()}, be a string\n",
       "containing at least one new line, or be a vector containing at least one\n",
       "string with a new line.\n",
       "\n",
       "Using a value of \\code{\\LinkA{clipboard()}{clipboard}} will read from the system clipboard.\n",
       "\n",
       "\\item[\\code{delim}] Single character used to separate fields within a record.\n",
       "\n",
       "\\item[\\code{quote}] Single character used to quote strings.\n",
       "\n",
       "\\item[\\code{escape\\_backslash}] Does the file use backslashes to escape special\n",
       "characters? This is more general than \\code{escape\\_double} as backslashes\n",
       "can be used to escape the delimiter character, the quote character, or\n",
       "to add special characters like \\AsIs{\\bsl{}\\bsl{}n}.\n",
       "\n",
       "\\item[\\code{escape\\_double}] Does the file escape quotes by doubling them?\n",
       "i.e. If this option is \\code{TRUE}, the value \\AsIs{\"\"\"\"} represents\n",
       "a single quote, \\AsIs{\\bsl{}\"}.\n",
       "\n",
       "\\item[\\code{col\\_names}] Either \\code{TRUE}, \\code{FALSE} or a character vector\n",
       "of column names.\n",
       "\n",
       "If \\code{TRUE}, the first row of the input will be used as the column\n",
       "names, and will not be included in the data frame. If \\code{FALSE}, column\n",
       "names will be generated automatically: X1, X2, X3 etc.\n",
       "\n",
       "If \\code{col\\_names} is a character vector, the values will be used as the\n",
       "names of the columns, and the first row of the input will be read into\n",
       "the first row of the output data frame.\n",
       "\n",
       "Missing (\\code{NA}) column names will generate a warning, and be filled\n",
       "in with dummy names \\code{...1}, \\code{...2} etc. Duplicate column names\n",
       "will generate a warning and be made unique, see \\code{name\\_repair} to control\n",
       "how this is done.\n",
       "\n",
       "\\item[\\code{col\\_types}] One of \\code{NULL}, a \\code{\\LinkA{cols()}{cols}} specification, or\n",
       "a string. See \\code{vignette(\"readr\")} for more details.\n",
       "\n",
       "If \\code{NULL}, all column types will be imputed from \\code{guess\\_max} rows\n",
       "on the input interspersed throughout the file. This is convenient (and\n",
       "fast), but not robust. If the imputation fails, you'll need to increase\n",
       "the \\code{guess\\_max} or supply the correct types yourself.\n",
       "\n",
       "Column specifications created by \\code{\\LinkA{list()}{list}} or \\code{\\LinkA{cols()}{cols}} must contain\n",
       "one column specification for each column. If you only want to read a\n",
       "subset of the columns, use \\code{\\LinkA{cols\\_only()}{cols.Rul.only}}.\n",
       "\n",
       "Alternatively, you can use a compact string representation where each\n",
       "character represents one column:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item{} c = character\n",
       "\\item{} i = integer\n",
       "\\item{} n = number\n",
       "\\item{} d = double\n",
       "\\item{} l = logical\n",
       "\\item{} f = factor\n",
       "\\item{} D = date\n",
       "\\item{} T = date time\n",
       "\\item{} t = time\n",
       "\\item{} ? = guess\n",
       "\\item{} \\_ or - = skip\n",
       "\n",
       "By default, reading a file without a column specification will print a\n",
       "message showing what \\code{readr} guessed they were. To remove this message,\n",
       "set \\code{show\\_col\\_types = FALSE} or set `options(readr.show\\_col\\_types = FALSE).\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "\\item[\\code{col\\_select}] Columns to include in the results. You can use the same\n",
       "mini-language as \\code{dplyr::select()} to refer to the columns by name. Use\n",
       "\\code{c()} or \\code{list()} to use more than one selection expression. Although this\n",
       "usage is less common, \\code{col\\_select} also accepts a numeric column index. See\n",
       "\\code{\\LinkA{?tidyselect::language}{?tidyselect::language}} for full details on the\n",
       "selection language.\n",
       "\n",
       "\\item[\\code{id}] The name of a column in which to store the file path. This is\n",
       "useful when reading multiple input files and there is data in the file\n",
       "paths, such as the data collection date. If \\code{NULL} (the default) no extra\n",
       "column is created.\n",
       "\n",
       "\\item[\\code{locale}] The locale controls defaults that vary from place to place.\n",
       "The default locale is US-centric (like R), but you can use\n",
       "\\code{\\LinkA{locale()}{locale}} to create your own locale that controls things like\n",
       "the default time zone, encoding, decimal mark, big mark, and day/month\n",
       "names.\n",
       "\n",
       "\\item[\\code{na}] Character vector of strings to interpret as missing values. Set this\n",
       "option to \\code{character()} to indicate no missing values.\n",
       "\n",
       "\\item[\\code{quoted\\_na}] \\strong{[Deprecated]} Should missing values\n",
       "inside quotes be treated as missing values (the default) or strings. This\n",
       "parameter is soft deprecated as of readr 2.0.0.\n",
       "\n",
       "\\item[\\code{comment}] A string used to identify comments. Any text after the\n",
       "comment characters will be silently ignored.\n",
       "\n",
       "\\item[\\code{trim\\_ws}] Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from\n",
       "each field before parsing it?\n",
       "\n",
       "\\item[\\code{skip}] Number of lines to skip before reading data. If \\code{comment} is\n",
       "supplied any commented lines are ignored \\emph{after} skipping.\n",
       "\n",
       "\\item[\\code{n\\_max}] Maximum number of lines to read.\n",
       "\n",
       "\\item[\\code{guess\\_max}] Maximum number of lines to use for guessing column types.\n",
       "See \\code{vignette(\"column-types\", package = \"readr\")} for more details.\n",
       "\n",
       "\\item[\\code{name\\_repair}] Handling of column names. The default behaviour is to\n",
       "ensure column names are \\code{\"unique\"}. Various repair strategies are\n",
       "supported:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item{} \\code{\"minimal\"}: No name repair or checks, beyond basic existence of names.\n",
       "\\item{} \\code{\"unique\"} (default value): Make sure names are unique and not empty.\n",
       "\\item{} \\code{\"check\\_unique\"}: no name repair, but check they are \\code{unique}.\n",
       "\\item{} \\code{\"universal\"}: Make the names \\code{unique} and syntactic.\n",
       "\\item{} A function: apply custom name repair (e.g., \\code{name\\_repair = make.names}\n",
       "for names in the style of base R).\n",
       "\\item{} A purrr-style anonymous function, see \\code{\\LinkA{rlang::as\\_function()}{rlang::as.Rul.function()}}.\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "This argument is passed on as \\code{repair} to \\code{\\LinkA{vctrs::vec\\_as\\_names()}{vctrs::vec.Rul.as.Rul.names()}}.\n",
       "See there for more details on these terms and the strategies used\n",
       "to enforce them.\n",
       "\n",
       "\\item[\\code{num\\_threads}] The number of processing threads to use for initial\n",
       "parsing and lazy reading of data. If your data contains newlines within\n",
       "fields the parser should automatically detect this and fall back to using\n",
       "one thread only. However if you know your file has newlines within quoted\n",
       "fields it is safest to set \\code{num\\_threads = 1} explicitly.\n",
       "\n",
       "\\item[\\code{progress}] Display a progress bar? By default it will only display\n",
       "in an interactive session and not while knitting a document. The automatic\n",
       "progress bar can be disabled by setting option \\code{readr.show\\_progress} to\n",
       "\\code{FALSE}.\n",
       "\n",
       "\\item[\\code{show\\_col\\_types}] If \\code{FALSE}, do not show the guessed column types. If\n",
       "\\code{TRUE} always show the column types, even if they are supplied. If \\code{NULL}\n",
       "(the default) only show the column types if they are not explicitly supplied\n",
       "by the \\code{col\\_types} argument.\n",
       "\n",
       "\\item[\\code{skip\\_empty\\_rows}] Should blank rows be ignored altogether? i.e. If this\n",
       "option is \\code{TRUE} then blank rows will not be represented at all.  If it is\n",
       "\\code{FALSE} then they will be represented by \\code{NA} values in all the columns.\n",
       "\n",
       "\\item[\\code{lazy}] Read values lazily? By default the file is initially only\n",
       "indexed and the values are read lazily when accessed. Lazy reading is\n",
       "useful interactively, particularly if you are only interested in a subset\n",
       "of the full dataset. \\emph{Note}, if you later write to the same file you read\n",
       "from you need to set \\code{lazy = FALSE}. On Windows the file will be locked\n",
       "and on other systems the memory map will become invalid.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Value}\n",
       "A \\code{\\LinkA{tibble()}{tibble}}. If there are parsing problems, a warning will alert you.\n",
       "You can retrieve the full details by calling \\code{\\LinkA{problems()}{problems}} on your dataset.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "# Input sources -------------------------------------------------------------\n",
       "# Read from a path\n",
       "read_csv(readr_example(\"mtcars.csv\"))\n",
       "read_csv(readr_example(\"mtcars.csv.zip\"))\n",
       "read_csv(readr_example(\"mtcars.csv.bz2\"))\n",
       "## Not run: \n",
       "# Including remote paths\n",
       "read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n",
       "\n",
       "## End(Not run)\n",
       "\n",
       "# Or directly from a string with `I()`\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"))\n",
       "\n",
       "# Column types --------------------------------------------------------------\n",
       "# By default, readr guesses the columns types, looking at `guess_max` rows.\n",
       "# You can override with a compact specification:\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = \"dc\")\n",
       "\n",
       "# Or with a list of column types:\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = list(col_double(), col_character()))\n",
       "\n",
       "# If there are parsing problems, you get a warning, and can extract\n",
       "# more details with problems()\n",
       "y <- read_csv(I(\"x\\n1\\n2\\nb\"), col_types = list(col_double()))\n",
       "y\n",
       "problems(y)\n",
       "\n",
       "# File types ----------------------------------------------------------------\n",
       "read_csv(I(\"a,b\\n1.0,2.0\"))\n",
       "read_csv2(I(\"a;b\\n1,0;2,0\"))\n",
       "read_tsv(I(\"a\\tb\\n1.0\\t2.0\"))\n",
       "read_delim(I(\"a|b\\n1.0|2.0\"), delim = \"|\")\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "read_delim                package:readr                R Documentation\n",
       "\n",
       "_\bR_\be_\ba_\bd _\ba _\bd_\be_\bl_\bi_\bm_\bi_\bt_\be_\bd _\bf_\bi_\bl_\be (_\bi_\bn_\bc_\bl_\bu_\bd_\bi_\bn_\bg _\bC_\bS_\bV _\ba_\bn_\bd _\bT_\bS_\bV) _\bi_\bn_\bt_\bo _\ba _\bt_\bi_\bb_\bb_\bl_\be\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     ‘read_csv()’ and ‘read_tsv()’ are special cases of the more\n",
       "     general ‘read_delim()’. They're useful for reading the most common\n",
       "     types of flat file data, comma separated values and tab separated\n",
       "     values, respectively. ‘read_csv2()’ uses ; for the field separator\n",
       "     and , for the decimal point. This format is common in some\n",
       "     European countries.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     read_delim(\n",
       "       file,\n",
       "       delim = NULL,\n",
       "       quote = \"\\\"\",\n",
       "       escape_backslash = FALSE,\n",
       "       escape_double = TRUE,\n",
       "       col_names = TRUE,\n",
       "       col_types = NULL,\n",
       "       col_select = NULL,\n",
       "       id = NULL,\n",
       "       locale = default_locale(),\n",
       "       na = c(\"\", \"NA\"),\n",
       "       quoted_na = TRUE,\n",
       "       comment = \"\",\n",
       "       trim_ws = FALSE,\n",
       "       skip = 0,\n",
       "       n_max = Inf,\n",
       "       guess_max = min(1000, n_max),\n",
       "       name_repair = \"unique\",\n",
       "       num_threads = readr_threads(),\n",
       "       progress = show_progress(),\n",
       "       show_col_types = should_show_types(),\n",
       "       skip_empty_rows = TRUE,\n",
       "       lazy = should_read_lazy()\n",
       "     )\n",
       "     \n",
       "     read_csv(\n",
       "       file,\n",
       "       col_names = TRUE,\n",
       "       col_types = NULL,\n",
       "       col_select = NULL,\n",
       "       id = NULL,\n",
       "       locale = default_locale(),\n",
       "       na = c(\"\", \"NA\"),\n",
       "       quoted_na = TRUE,\n",
       "       quote = \"\\\"\",\n",
       "       comment = \"\",\n",
       "       trim_ws = TRUE,\n",
       "       skip = 0,\n",
       "       n_max = Inf,\n",
       "       guess_max = min(1000, n_max),\n",
       "       name_repair = \"unique\",\n",
       "       num_threads = readr_threads(),\n",
       "       progress = show_progress(),\n",
       "       show_col_types = should_show_types(),\n",
       "       skip_empty_rows = TRUE,\n",
       "       lazy = should_read_lazy()\n",
       "     )\n",
       "     \n",
       "     read_csv2(\n",
       "       file,\n",
       "       col_names = TRUE,\n",
       "       col_types = NULL,\n",
       "       col_select = NULL,\n",
       "       id = NULL,\n",
       "       locale = default_locale(),\n",
       "       na = c(\"\", \"NA\"),\n",
       "       quoted_na = TRUE,\n",
       "       quote = \"\\\"\",\n",
       "       comment = \"\",\n",
       "       trim_ws = TRUE,\n",
       "       skip = 0,\n",
       "       n_max = Inf,\n",
       "       guess_max = min(1000, n_max),\n",
       "       progress = show_progress(),\n",
       "       name_repair = \"unique\",\n",
       "       num_threads = readr_threads(),\n",
       "       show_col_types = should_show_types(),\n",
       "       skip_empty_rows = TRUE,\n",
       "       lazy = should_read_lazy()\n",
       "     )\n",
       "     \n",
       "     read_tsv(\n",
       "       file,\n",
       "       col_names = TRUE,\n",
       "       col_types = NULL,\n",
       "       col_select = NULL,\n",
       "       id = NULL,\n",
       "       locale = default_locale(),\n",
       "       na = c(\"\", \"NA\"),\n",
       "       quoted_na = TRUE,\n",
       "       quote = \"\\\"\",\n",
       "       comment = \"\",\n",
       "       trim_ws = TRUE,\n",
       "       skip = 0,\n",
       "       n_max = Inf,\n",
       "       guess_max = min(1000, n_max),\n",
       "       progress = show_progress(),\n",
       "       name_repair = \"unique\",\n",
       "       num_threads = readr_threads(),\n",
       "       show_col_types = should_show_types(),\n",
       "       skip_empty_rows = TRUE,\n",
       "       lazy = should_read_lazy()\n",
       "     )\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "    file: Either a path to a file, a connection, or literal data\n",
       "          (either a single string or a raw vector).\n",
       "\n",
       "          Files ending in ‘.gz’, ‘.bz2’, ‘.xz’, or ‘.zip’ will be\n",
       "          automatically uncompressed. Files starting with http://,\n",
       "          https://, ftp://, or ftps:// will be automatically\n",
       "          downloaded. Remote gz files can also be automatically\n",
       "          downloaded and decompressed.\n",
       "\n",
       "          Literal data is most useful for examples and tests. To be\n",
       "          recognised as literal data, the input must be either wrapped\n",
       "          with ‘I()’, be a string containing at least one new line, or\n",
       "          be a vector containing at least one string with a new line.\n",
       "\n",
       "          Using a value of ‘clipboard()’ will read from the system\n",
       "          clipboard.\n",
       "\n",
       "   delim: Single character used to separate fields within a record.\n",
       "\n",
       "   quote: Single character used to quote strings.\n",
       "\n",
       "escape_backslash: Does the file use backslashes to escape special\n",
       "          characters? This is more general than ‘escape_double’ as\n",
       "          backslashes can be used to escape the delimiter character,\n",
       "          the quote character, or to add special characters like \\\\n.\n",
       "\n",
       "escape_double: Does the file escape quotes by doubling them? i.e. If\n",
       "          this option is ‘TRUE’, the value \"\"\"\" represents a single\n",
       "          quote, \\\".\n",
       "\n",
       "col_names: Either ‘TRUE’, ‘FALSE’ or a character vector of column\n",
       "          names.\n",
       "\n",
       "          If ‘TRUE’, the first row of the input will be used as the\n",
       "          column names, and will not be included in the data frame. If\n",
       "          ‘FALSE’, column names will be generated automatically: X1,\n",
       "          X2, X3 etc.\n",
       "\n",
       "          If ‘col_names’ is a character vector, the values will be used\n",
       "          as the names of the columns, and the first row of the input\n",
       "          will be read into the first row of the output data frame.\n",
       "\n",
       "          Missing (‘NA’) column names will generate a warning, and be\n",
       "          filled in with dummy names ‘...1’, ‘...2’ etc. Duplicate\n",
       "          column names will generate a warning and be made unique, see\n",
       "          ‘name_repair’ to control how this is done.\n",
       "\n",
       "col_types: One of ‘NULL’, a ‘cols()’ specification, or a string. See\n",
       "          ‘vignette(\"readr\")’ for more details.\n",
       "\n",
       "          If ‘NULL’, all column types will be imputed from ‘guess_max’\n",
       "          rows on the input interspersed throughout the file. This is\n",
       "          convenient (and fast), but not robust. If the imputation\n",
       "          fails, you'll need to increase the ‘guess_max’ or supply the\n",
       "          correct types yourself.\n",
       "\n",
       "          Column specifications created by ‘list()’ or ‘cols()’ must\n",
       "          contain one column specification for each column. If you only\n",
       "          want to read a subset of the columns, use ‘cols_only()’.\n",
       "\n",
       "          Alternatively, you can use a compact string representation\n",
       "          where each character represents one column:\n",
       "\n",
       "            • c = character\n",
       "\n",
       "            • i = integer\n",
       "\n",
       "            • n = number\n",
       "\n",
       "            • d = double\n",
       "\n",
       "            • l = logical\n",
       "\n",
       "            • f = factor\n",
       "\n",
       "            • D = date\n",
       "\n",
       "            • T = date time\n",
       "\n",
       "            • t = time\n",
       "\n",
       "            • ? = guess\n",
       "\n",
       "            • _ or - = skip\n",
       "\n",
       "              By default, reading a file without a column specification\n",
       "              will print a message showing what ‘readr’ guessed they\n",
       "              were. To remove this message, set ‘show_col_types =\n",
       "              FALSE’ or set `options(readr.show_col_types = FALSE).\n",
       "\n",
       "col_select: Columns to include in the results. You can use the same\n",
       "          mini-language as ‘dplyr::select()’ to refer to the columns by\n",
       "          name. Use ‘c()’ or ‘list()’ to use more than one selection\n",
       "          expression. Although this usage is less common, ‘col_select’\n",
       "          also accepts a numeric column index. See\n",
       "          ‘?tidyselect::language’ for full details on the selection\n",
       "          language.\n",
       "\n",
       "      id: The name of a column in which to store the file path. This is\n",
       "          useful when reading multiple input files and there is data in\n",
       "          the file paths, such as the data collection date. If ‘NULL’\n",
       "          (the default) no extra column is created.\n",
       "\n",
       "  locale: The locale controls defaults that vary from place to place.\n",
       "          The default locale is US-centric (like R), but you can use\n",
       "          ‘locale()’ to create your own locale that controls things\n",
       "          like the default time zone, encoding, decimal mark, big mark,\n",
       "          and day/month names.\n",
       "\n",
       "      na: Character vector of strings to interpret as missing values.\n",
       "          Set this option to ‘character()’ to indicate no missing\n",
       "          values.\n",
       "\n",
       "quoted_na: *[Deprecated]* Should missing values inside quotes be\n",
       "          treated as missing values (the default) or strings. This\n",
       "          parameter is soft deprecated as of readr 2.0.0.\n",
       "\n",
       " comment: A string used to identify comments. Any text after the\n",
       "          comment characters will be silently ignored.\n",
       "\n",
       " trim_ws: Should leading and trailing whitespace (ASCII spaces and\n",
       "          tabs) be trimmed from each field before parsing it?\n",
       "\n",
       "    skip: Number of lines to skip before reading data. If ‘comment’ is\n",
       "          supplied any commented lines are ignored _after_ skipping.\n",
       "\n",
       "   n_max: Maximum number of lines to read.\n",
       "\n",
       "guess_max: Maximum number of lines to use for guessing column types.\n",
       "          See ‘vignette(\"column-types\", package = \"readr\")’ for more\n",
       "          details.\n",
       "\n",
       "name_repair: Handling of column names. The default behaviour is to\n",
       "          ensure column names are ‘\"unique\"’. Various repair strategies\n",
       "          are supported:\n",
       "\n",
       "            • ‘\"minimal\"’: No name repair or checks, beyond basic\n",
       "              existence of names.\n",
       "\n",
       "            • ‘\"unique\"’ (default value): Make sure names are unique\n",
       "              and not empty.\n",
       "\n",
       "            • ‘\"check_unique\"’: no name repair, but check they are\n",
       "              ‘unique’.\n",
       "\n",
       "            • ‘\"universal\"’: Make the names ‘unique’ and syntactic.\n",
       "\n",
       "            • A function: apply custom name repair (e.g., ‘name_repair\n",
       "              = make.names’ for names in the style of base R).\n",
       "\n",
       "            • A purrr-style anonymous function, see\n",
       "              ‘rlang::as_function()’.\n",
       "\n",
       "          This argument is passed on as ‘repair’ to\n",
       "          ‘vctrs::vec_as_names()’. See there for more details on these\n",
       "          terms and the strategies used to enforce them.\n",
       "\n",
       "num_threads: The number of processing threads to use for initial\n",
       "          parsing and lazy reading of data. If your data contains\n",
       "          newlines within fields the parser should automatically detect\n",
       "          this and fall back to using one thread only. However if you\n",
       "          know your file has newlines within quoted fields it is safest\n",
       "          to set ‘num_threads = 1’ explicitly.\n",
       "\n",
       "progress: Display a progress bar? By default it will only display in an\n",
       "          interactive session and not while knitting a document. The\n",
       "          automatic progress bar can be disabled by setting option\n",
       "          ‘readr.show_progress’ to ‘FALSE’.\n",
       "\n",
       "show_col_types: If ‘FALSE’, do not show the guessed column types. If\n",
       "          ‘TRUE’ always show the column types, even if they are\n",
       "          supplied. If ‘NULL’ (the default) only show the column types\n",
       "          if they are not explicitly supplied by the ‘col_types’\n",
       "          argument.\n",
       "\n",
       "skip_empty_rows: Should blank rows be ignored altogether? i.e. If this\n",
       "          option is ‘TRUE’ then blank rows will not be represented at\n",
       "          all.  If it is ‘FALSE’ then they will be represented by ‘NA’\n",
       "          values in all the columns.\n",
       "\n",
       "    lazy: Read values lazily? By default the file is initially only\n",
       "          indexed and the values are read lazily when accessed. Lazy\n",
       "          reading is useful interactively, particularly if you are only\n",
       "          interested in a subset of the full dataset. _Note_, if you\n",
       "          later write to the same file you read from you need to set\n",
       "          ‘lazy = FALSE’. On Windows the file will be locked and on\n",
       "          other systems the memory map will become invalid.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A ‘tibble()’. If there are parsing problems, a warning will alert\n",
       "     you. You can retrieve the full details by calling ‘problems()’ on\n",
       "     your dataset.\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     # Input sources -------------------------------------------------------------\n",
       "     # Read from a path\n",
       "     read_csv(readr_example(\"mtcars.csv\"))\n",
       "     read_csv(readr_example(\"mtcars.csv.zip\"))\n",
       "     read_csv(readr_example(\"mtcars.csv.bz2\"))\n",
       "     ## Not run:\n",
       "     \n",
       "     # Including remote paths\n",
       "     read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n",
       "     ## End(Not run)\n",
       "     \n",
       "     \n",
       "     # Or directly from a string with `I()`\n",
       "     read_csv(I(\"x,y\\n1,2\\n3,4\"))\n",
       "     \n",
       "     # Column types --------------------------------------------------------------\n",
       "     # By default, readr guesses the columns types, looking at `guess_max` rows.\n",
       "     # You can override with a compact specification:\n",
       "     read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = \"dc\")\n",
       "     \n",
       "     # Or with a list of column types:\n",
       "     read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = list(col_double(), col_character()))\n",
       "     \n",
       "     # If there are parsing problems, you get a warning, and can extract\n",
       "     # more details with problems()\n",
       "     y <- read_csv(I(\"x\\n1\\n2\\nb\"), col_types = list(col_double()))\n",
       "     y\n",
       "     problems(y)\n",
       "     \n",
       "     # File types ----------------------------------------------------------------\n",
       "     read_csv(I(\"a,b\\n1.0,2.0\"))\n",
       "     read_csv2(I(\"a;b\\n1,0;2,0\"))\n",
       "     read_tsv(I(\"a\\tb\\n1.0\\t2.0\"))\n",
       "     read_delim(I(\"a|b\\n1.0|2.0\"), delim = \"|\")\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48f366a-0ac4-4e0f-8f75-4e1e2b75bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m303\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (2): X12, X13\n",
      "\u001b[32mdbl\u001b[39m (12): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X14\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'X1'</li><li>'X2'</li><li>'X3'</li><li>'X4'</li><li>'X5'</li><li>'X6'</li><li>'X7'</li><li>'X8'</li><li>'X9'</li><li>'X10'</li><li>'X11'</li><li>'X12'</li><li>'X13'</li><li>'X14'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'X1'\n",
       "\\item 'X2'\n",
       "\\item 'X3'\n",
       "\\item 'X4'\n",
       "\\item 'X5'\n",
       "\\item 'X6'\n",
       "\\item 'X7'\n",
       "\\item 'X8'\n",
       "\\item 'X9'\n",
       "\\item 'X10'\n",
       "\\item 'X11'\n",
       "\\item 'X12'\n",
       "\\item 'X13'\n",
       "\\item 'X14'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'X1'\n",
       "2. 'X2'\n",
       "3. 'X3'\n",
       "4. 'X4'\n",
       "5. 'X5'\n",
       "6. 'X6'\n",
       "7. 'X7'\n",
       "8. 'X8'\n",
       "9. 'X9'\n",
       "10. 'X10'\n",
       "11. 'X11'\n",
       "12. 'X12'\n",
       "13. 'X13'\n",
       "14. 'X14'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"X1\"  \"X2\"  \"X3\"  \"X4\"  \"X5\"  \"X6\"  \"X7\"  \"X8\"  \"X9\"  \"X10\" \"X11\" \"X12\"\n",
       "[13] \"X13\" \"X14\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A spec_tbl_df: 303 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Age</th><th scope=col>Sex</th><th scope=col>Chest Pain Type</th><th scope=col>Resting blood Pressure</th><th scope=col>Cholesterol</th><th scope=col>Fasting Blood Sugar</th><th scope=col>Resting ECG</th><th scope=col>Max Heart Rate</th><th scope=col>Excersize Induced Angina</th><th scope=col>ST Depression</th><th scope=col>Slope</th><th scope=col>Number of Major Vessels</th><th scope=col>Thal</th><th scope=col>Heart Disease Diagnosis</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>63</td><td>1</td><td>1</td><td>145</td><td>233</td><td>1</td><td>2</td><td>150</td><td>0</td><td>2.3</td><td>3</td><td>0.0</td><td>6.0</td><td>0</td></tr>\n",
       "\t<tr><td>67</td><td>1</td><td>4</td><td>160</td><td>286</td><td>0</td><td>2</td><td>108</td><td>1</td><td>1.5</td><td>2</td><td>3.0</td><td>3.0</td><td>2</td></tr>\n",
       "\t<tr><td>67</td><td>1</td><td>4</td><td>120</td><td>229</td><td>0</td><td>2</td><td>129</td><td>1</td><td>2.6</td><td>2</td><td>2.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>37</td><td>1</td><td>3</td><td>130</td><td>250</td><td>0</td><td>0</td><td>187</td><td>0</td><td>3.5</td><td>3</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>41</td><td>0</td><td>2</td><td>130</td><td>204</td><td>0</td><td>2</td><td>172</td><td>0</td><td>1.4</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>56</td><td>1</td><td>2</td><td>120</td><td>236</td><td>0</td><td>0</td><td>178</td><td>0</td><td>0.8</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>62</td><td>0</td><td>4</td><td>140</td><td>268</td><td>0</td><td>2</td><td>160</td><td>0</td><td>3.6</td><td>3</td><td>2.0</td><td>3.0</td><td>3</td></tr>\n",
       "\t<tr><td>57</td><td>0</td><td>4</td><td>120</td><td>354</td><td>0</td><td>0</td><td>163</td><td>1</td><td>0.6</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>63</td><td>1</td><td>4</td><td>130</td><td>254</td><td>0</td><td>2</td><td>147</td><td>0</td><td>1.4</td><td>2</td><td>1.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>53</td><td>1</td><td>4</td><td>140</td><td>203</td><td>1</td><td>2</td><td>155</td><td>1</td><td>3.1</td><td>3</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>4</td><td>140</td><td>192</td><td>0</td><td>0</td><td>148</td><td>0</td><td>0.4</td><td>2</td><td>0.0</td><td>6.0</td><td>0</td></tr>\n",
       "\t<tr><td>56</td><td>0</td><td>2</td><td>140</td><td>294</td><td>0</td><td>2</td><td>153</td><td>0</td><td>1.3</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>56</td><td>1</td><td>3</td><td>130</td><td>256</td><td>1</td><td>2</td><td>142</td><td>1</td><td>0.6</td><td>2</td><td>1.0</td><td>6.0</td><td>2</td></tr>\n",
       "\t<tr><td>44</td><td>1</td><td>2</td><td>120</td><td>263</td><td>0</td><td>0</td><td>173</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>7.0</td><td>0</td></tr>\n",
       "\t<tr><td>52</td><td>1</td><td>3</td><td>172</td><td>199</td><td>1</td><td>0</td><td>162</td><td>0</td><td>0.5</td><td>1</td><td>0.0</td><td>7.0</td><td>0</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>3</td><td>150</td><td>168</td><td>0</td><td>0</td><td>174</td><td>0</td><td>1.6</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>48</td><td>1</td><td>2</td><td>110</td><td>229</td><td>0</td><td>0</td><td>168</td><td>0</td><td>1.0</td><td>3</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>54</td><td>1</td><td>4</td><td>140</td><td>239</td><td>0</td><td>0</td><td>160</td><td>0</td><td>1.2</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>48</td><td>0</td><td>3</td><td>130</td><td>275</td><td>0</td><td>0</td><td>139</td><td>0</td><td>0.2</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>49</td><td>1</td><td>2</td><td>130</td><td>266</td><td>0</td><td>0</td><td>171</td><td>0</td><td>0.6</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>64</td><td>1</td><td>1</td><td>110</td><td>211</td><td>0</td><td>2</td><td>144</td><td>1</td><td>1.8</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>58</td><td>0</td><td>1</td><td>150</td><td>283</td><td>1</td><td>2</td><td>162</td><td>0</td><td>1.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>58</td><td>1</td><td>2</td><td>120</td><td>284</td><td>0</td><td>2</td><td>160</td><td>0</td><td>1.8</td><td>2</td><td>0.0</td><td>3.0</td><td>1</td></tr>\n",
       "\t<tr><td>58</td><td>1</td><td>3</td><td>132</td><td>224</td><td>0</td><td>2</td><td>173</td><td>0</td><td>3.2</td><td>1</td><td>2.0</td><td>7.0</td><td>3</td></tr>\n",
       "\t<tr><td>60</td><td>1</td><td>4</td><td>130</td><td>206</td><td>0</td><td>2</td><td>132</td><td>1</td><td>2.4</td><td>2</td><td>2.0</td><td>7.0</td><td>4</td></tr>\n",
       "\t<tr><td>50</td><td>0</td><td>3</td><td>120</td><td>219</td><td>0</td><td>0</td><td>158</td><td>0</td><td>1.6</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>58</td><td>0</td><td>3</td><td>120</td><td>340</td><td>0</td><td>0</td><td>172</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>66</td><td>0</td><td>1</td><td>150</td><td>226</td><td>0</td><td>0</td><td>114</td><td>0</td><td>2.6</td><td>3</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>43</td><td>1</td><td>4</td><td>150</td><td>247</td><td>0</td><td>0</td><td>171</td><td>0</td><td>1.5</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>40</td><td>1</td><td>4</td><td>110</td><td>167</td><td>0</td><td>2</td><td>114</td><td>1</td><td>2.0</td><td>2</td><td>0.0</td><td>7.0</td><td>3</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>71</td><td>0</td><td>4</td><td>112</td><td>149</td><td>0</td><td>0</td><td>125</td><td>0</td><td>1.6</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>59</td><td>1</td><td>1</td><td>134</td><td>204</td><td>0</td><td>0</td><td>162</td><td>0</td><td>0.8</td><td>1</td><td>2.0</td><td>3.0</td><td>1</td></tr>\n",
       "\t<tr><td>64</td><td>1</td><td>1</td><td>170</td><td>227</td><td>0</td><td>2</td><td>155</td><td>0</td><td>0.6</td><td>2</td><td>0.0</td><td>7.0</td><td>0</td></tr>\n",
       "\t<tr><td>66</td><td>0</td><td>3</td><td>146</td><td>278</td><td>0</td><td>2</td><td>152</td><td>0</td><td>0.0</td><td>2</td><td>1.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>39</td><td>0</td><td>3</td><td>138</td><td>220</td><td>0</td><td>0</td><td>152</td><td>0</td><td>0.0</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>2</td><td>154</td><td>232</td><td>0</td><td>2</td><td>164</td><td>0</td><td>0.0</td><td>1</td><td>1.0</td><td>3.0</td><td>1</td></tr>\n",
       "\t<tr><td>58</td><td>0</td><td>4</td><td>130</td><td>197</td><td>0</td><td>0</td><td>131</td><td>0</td><td>0.6</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>4</td><td>110</td><td>335</td><td>0</td><td>0</td><td>143</td><td>1</td><td>3.0</td><td>2</td><td>1.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>47</td><td>1</td><td>3</td><td>130</td><td>253</td><td>0</td><td>0</td><td>179</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>55</td><td>0</td><td>4</td><td>128</td><td>205</td><td>0</td><td>1</td><td>130</td><td>1</td><td>2.0</td><td>2</td><td>1.0</td><td>7.0</td><td>3</td></tr>\n",
       "\t<tr><td>35</td><td>1</td><td>2</td><td>122</td><td>192</td><td>0</td><td>0</td><td>174</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>61</td><td>1</td><td>4</td><td>148</td><td>203</td><td>0</td><td>0</td><td>161</td><td>0</td><td>0.0</td><td>1</td><td>1.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>58</td><td>1</td><td>4</td><td>114</td><td>318</td><td>0</td><td>1</td><td>140</td><td>0</td><td>4.4</td><td>3</td><td>3.0</td><td>6.0</td><td>4</td></tr>\n",
       "\t<tr><td>58</td><td>0</td><td>4</td><td>170</td><td>225</td><td>1</td><td>2</td><td>146</td><td>1</td><td>2.8</td><td>2</td><td>2.0</td><td>6.0</td><td>2</td></tr>\n",
       "\t<tr><td>58</td><td>1</td><td>2</td><td>125</td><td>220</td><td>0</td><td>0</td><td>144</td><td>0</td><td>0.4</td><td>2</td><td>?  </td><td>7.0</td><td>0</td></tr>\n",
       "\t<tr><td>56</td><td>1</td><td>2</td><td>130</td><td>221</td><td>0</td><td>2</td><td>163</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>7.0</td><td>0</td></tr>\n",
       "\t<tr><td>56</td><td>1</td><td>2</td><td>120</td><td>240</td><td>0</td><td>0</td><td>169</td><td>0</td><td>0.0</td><td>3</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>67</td><td>1</td><td>3</td><td>152</td><td>212</td><td>0</td><td>2</td><td>150</td><td>0</td><td>0.8</td><td>2</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>55</td><td>0</td><td>2</td><td>132</td><td>342</td><td>0</td><td>0</td><td>166</td><td>0</td><td>1.2</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>44</td><td>1</td><td>4</td><td>120</td><td>169</td><td>0</td><td>0</td><td>144</td><td>1</td><td>2.8</td><td>3</td><td>0.0</td><td>6.0</td><td>2</td></tr>\n",
       "\t<tr><td>63</td><td>1</td><td>4</td><td>140</td><td>187</td><td>0</td><td>2</td><td>144</td><td>1</td><td>4.0</td><td>1</td><td>2.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>63</td><td>0</td><td>4</td><td>124</td><td>197</td><td>0</td><td>0</td><td>136</td><td>1</td><td>0.0</td><td>2</td><td>0.0</td><td>3.0</td><td>1</td></tr>\n",
       "\t<tr><td>41</td><td>1</td><td>2</td><td>120</td><td>157</td><td>0</td><td>0</td><td>182</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>59</td><td>1</td><td>4</td><td>164</td><td>176</td><td>1</td><td>2</td><td> 90</td><td>0</td><td>1.0</td><td>2</td><td>2.0</td><td>6.0</td><td>3</td></tr>\n",
       "\t<tr><td>57</td><td>0</td><td>4</td><td>140</td><td>241</td><td>0</td><td>0</td><td>123</td><td>1</td><td>0.2</td><td>2</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>45</td><td>1</td><td>1</td><td>110</td><td>264</td><td>0</td><td>0</td><td>132</td><td>0</td><td>1.2</td><td>2</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>68</td><td>1</td><td>4</td><td>144</td><td>193</td><td>1</td><td>0</td><td>141</td><td>0</td><td>3.4</td><td>2</td><td>2.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>4</td><td>130</td><td>131</td><td>0</td><td>0</td><td>115</td><td>1</td><td>1.2</td><td>2</td><td>1.0</td><td>7.0</td><td>3</td></tr>\n",
       "\t<tr><td>57</td><td>0</td><td>2</td><td>130</td><td>236</td><td>0</td><td>2</td><td>174</td><td>0</td><td>0.0</td><td>2</td><td>1.0</td><td>3.0</td><td>1</td></tr>\n",
       "\t<tr><td>38</td><td>1</td><td>3</td><td>138</td><td>175</td><td>0</td><td>0</td><td>173</td><td>0</td><td>0.0</td><td>1</td><td>?  </td><td>3.0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 303 × 14\n",
       "\\begin{tabular}{llllllllllllll}\n",
       " Age & Sex & Chest Pain Type & Resting blood Pressure & Cholesterol & Fasting Blood Sugar & Resting ECG & Max Heart Rate & Excersize Induced Angina & ST Depression & Slope & Number of Major Vessels & Thal & Heart Disease Diagnosis\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 63 & 1 & 1 & 145 & 233 & 1 & 2 & 150 & 0 & 2.3 & 3 & 0.0 & 6.0 & 0\\\\\n",
       "\t 67 & 1 & 4 & 160 & 286 & 0 & 2 & 108 & 1 & 1.5 & 2 & 3.0 & 3.0 & 2\\\\\n",
       "\t 67 & 1 & 4 & 120 & 229 & 0 & 2 & 129 & 1 & 2.6 & 2 & 2.0 & 7.0 & 1\\\\\n",
       "\t 37 & 1 & 3 & 130 & 250 & 0 & 0 & 187 & 0 & 3.5 & 3 & 0.0 & 3.0 & 0\\\\\n",
       "\t 41 & 0 & 2 & 130 & 204 & 0 & 2 & 172 & 0 & 1.4 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 56 & 1 & 2 & 120 & 236 & 0 & 0 & 178 & 0 & 0.8 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 62 & 0 & 4 & 140 & 268 & 0 & 2 & 160 & 0 & 3.6 & 3 & 2.0 & 3.0 & 3\\\\\n",
       "\t 57 & 0 & 4 & 120 & 354 & 0 & 0 & 163 & 1 & 0.6 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 63 & 1 & 4 & 130 & 254 & 0 & 2 & 147 & 0 & 1.4 & 2 & 1.0 & 7.0 & 2\\\\\n",
       "\t 53 & 1 & 4 & 140 & 203 & 1 & 2 & 155 & 1 & 3.1 & 3 & 0.0 & 7.0 & 1\\\\\n",
       "\t 57 & 1 & 4 & 140 & 192 & 0 & 0 & 148 & 0 & 0.4 & 2 & 0.0 & 6.0 & 0\\\\\n",
       "\t 56 & 0 & 2 & 140 & 294 & 0 & 2 & 153 & 0 & 1.3 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 56 & 1 & 3 & 130 & 256 & 1 & 2 & 142 & 1 & 0.6 & 2 & 1.0 & 6.0 & 2\\\\\n",
       "\t 44 & 1 & 2 & 120 & 263 & 0 & 0 & 173 & 0 & 0.0 & 1 & 0.0 & 7.0 & 0\\\\\n",
       "\t 52 & 1 & 3 & 172 & 199 & 1 & 0 & 162 & 0 & 0.5 & 1 & 0.0 & 7.0 & 0\\\\\n",
       "\t 57 & 1 & 3 & 150 & 168 & 0 & 0 & 174 & 0 & 1.6 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 48 & 1 & 2 & 110 & 229 & 0 & 0 & 168 & 0 & 1.0 & 3 & 0.0 & 7.0 & 1\\\\\n",
       "\t 54 & 1 & 4 & 140 & 239 & 0 & 0 & 160 & 0 & 1.2 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 48 & 0 & 3 & 130 & 275 & 0 & 0 & 139 & 0 & 0.2 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 49 & 1 & 2 & 130 & 266 & 0 & 0 & 171 & 0 & 0.6 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 64 & 1 & 1 & 110 & 211 & 0 & 2 & 144 & 1 & 1.8 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 58 & 0 & 1 & 150 & 283 & 1 & 2 & 162 & 0 & 1.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 58 & 1 & 2 & 120 & 284 & 0 & 2 & 160 & 0 & 1.8 & 2 & 0.0 & 3.0 & 1\\\\\n",
       "\t 58 & 1 & 3 & 132 & 224 & 0 & 2 & 173 & 0 & 3.2 & 1 & 2.0 & 7.0 & 3\\\\\n",
       "\t 60 & 1 & 4 & 130 & 206 & 0 & 2 & 132 & 1 & 2.4 & 2 & 2.0 & 7.0 & 4\\\\\n",
       "\t 50 & 0 & 3 & 120 & 219 & 0 & 0 & 158 & 0 & 1.6 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 58 & 0 & 3 & 120 & 340 & 0 & 0 & 172 & 0 & 0.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 66 & 0 & 1 & 150 & 226 & 0 & 0 & 114 & 0 & 2.6 & 3 & 0.0 & 3.0 & 0\\\\\n",
       "\t 43 & 1 & 4 & 150 & 247 & 0 & 0 & 171 & 0 & 1.5 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 40 & 1 & 4 & 110 & 167 & 0 & 2 & 114 & 1 & 2.0 & 2 & 0.0 & 7.0 & 3\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 71 & 0 & 4 & 112 & 149 & 0 & 0 & 125 & 0 & 1.6 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 59 & 1 & 1 & 134 & 204 & 0 & 0 & 162 & 0 & 0.8 & 1 & 2.0 & 3.0 & 1\\\\\n",
       "\t 64 & 1 & 1 & 170 & 227 & 0 & 2 & 155 & 0 & 0.6 & 2 & 0.0 & 7.0 & 0\\\\\n",
       "\t 66 & 0 & 3 & 146 & 278 & 0 & 2 & 152 & 0 & 0.0 & 2 & 1.0 & 3.0 & 0\\\\\n",
       "\t 39 & 0 & 3 & 138 & 220 & 0 & 0 & 152 & 0 & 0.0 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 57 & 1 & 2 & 154 & 232 & 0 & 2 & 164 & 0 & 0.0 & 1 & 1.0 & 3.0 & 1\\\\\n",
       "\t 58 & 0 & 4 & 130 & 197 & 0 & 0 & 131 & 0 & 0.6 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 57 & 1 & 4 & 110 & 335 & 0 & 0 & 143 & 1 & 3.0 & 2 & 1.0 & 7.0 & 2\\\\\n",
       "\t 47 & 1 & 3 & 130 & 253 & 0 & 0 & 179 & 0 & 0.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 55 & 0 & 4 & 128 & 205 & 0 & 1 & 130 & 1 & 2.0 & 2 & 1.0 & 7.0 & 3\\\\\n",
       "\t 35 & 1 & 2 & 122 & 192 & 0 & 0 & 174 & 0 & 0.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 61 & 1 & 4 & 148 & 203 & 0 & 0 & 161 & 0 & 0.0 & 1 & 1.0 & 7.0 & 2\\\\\n",
       "\t 58 & 1 & 4 & 114 & 318 & 0 & 1 & 140 & 0 & 4.4 & 3 & 3.0 & 6.0 & 4\\\\\n",
       "\t 58 & 0 & 4 & 170 & 225 & 1 & 2 & 146 & 1 & 2.8 & 2 & 2.0 & 6.0 & 2\\\\\n",
       "\t 58 & 1 & 2 & 125 & 220 & 0 & 0 & 144 & 0 & 0.4 & 2 & ?   & 7.0 & 0\\\\\n",
       "\t 56 & 1 & 2 & 130 & 221 & 0 & 2 & 163 & 0 & 0.0 & 1 & 0.0 & 7.0 & 0\\\\\n",
       "\t 56 & 1 & 2 & 120 & 240 & 0 & 0 & 169 & 0 & 0.0 & 3 & 0.0 & 3.0 & 0\\\\\n",
       "\t 67 & 1 & 3 & 152 & 212 & 0 & 2 & 150 & 0 & 0.8 & 2 & 0.0 & 7.0 & 1\\\\\n",
       "\t 55 & 0 & 2 & 132 & 342 & 0 & 0 & 166 & 0 & 1.2 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 44 & 1 & 4 & 120 & 169 & 0 & 0 & 144 & 1 & 2.8 & 3 & 0.0 & 6.0 & 2\\\\\n",
       "\t 63 & 1 & 4 & 140 & 187 & 0 & 2 & 144 & 1 & 4.0 & 1 & 2.0 & 7.0 & 2\\\\\n",
       "\t 63 & 0 & 4 & 124 & 197 & 0 & 0 & 136 & 1 & 0.0 & 2 & 0.0 & 3.0 & 1\\\\\n",
       "\t 41 & 1 & 2 & 120 & 157 & 0 & 0 & 182 & 0 & 0.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 59 & 1 & 4 & 164 & 176 & 1 & 2 &  90 & 0 & 1.0 & 2 & 2.0 & 6.0 & 3\\\\\n",
       "\t 57 & 0 & 4 & 140 & 241 & 0 & 0 & 123 & 1 & 0.2 & 2 & 0.0 & 7.0 & 1\\\\\n",
       "\t 45 & 1 & 1 & 110 & 264 & 0 & 0 & 132 & 0 & 1.2 & 2 & 0.0 & 7.0 & 1\\\\\n",
       "\t 68 & 1 & 4 & 144 & 193 & 1 & 0 & 141 & 0 & 3.4 & 2 & 2.0 & 7.0 & 2\\\\\n",
       "\t 57 & 1 & 4 & 130 & 131 & 0 & 0 & 115 & 1 & 1.2 & 2 & 1.0 & 7.0 & 3\\\\\n",
       "\t 57 & 0 & 2 & 130 & 236 & 0 & 2 & 174 & 0 & 0.0 & 2 & 1.0 & 3.0 & 1\\\\\n",
       "\t 38 & 1 & 3 & 138 & 175 & 0 & 0 & 173 & 0 & 0.0 & 1 & ?   & 3.0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 303 × 14\n",
       "\n",
       "| Age &lt;dbl&gt; | Sex &lt;dbl&gt; | Chest Pain Type &lt;dbl&gt; | Resting blood Pressure &lt;dbl&gt; | Cholesterol &lt;dbl&gt; | Fasting Blood Sugar &lt;dbl&gt; | Resting ECG &lt;dbl&gt; | Max Heart Rate &lt;dbl&gt; | Excersize Induced Angina &lt;dbl&gt; | ST Depression &lt;dbl&gt; | Slope &lt;dbl&gt; | Number of Major Vessels &lt;chr&gt; | Thal &lt;chr&gt; | Heart Disease Diagnosis &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 63 | 1 | 1 | 145 | 233 | 1 | 2 | 150 | 0 | 2.3 | 3 | 0.0 | 6.0 | 0 |\n",
       "| 67 | 1 | 4 | 160 | 286 | 0 | 2 | 108 | 1 | 1.5 | 2 | 3.0 | 3.0 | 2 |\n",
       "| 67 | 1 | 4 | 120 | 229 | 0 | 2 | 129 | 1 | 2.6 | 2 | 2.0 | 7.0 | 1 |\n",
       "| 37 | 1 | 3 | 130 | 250 | 0 | 0 | 187 | 0 | 3.5 | 3 | 0.0 | 3.0 | 0 |\n",
       "| 41 | 0 | 2 | 130 | 204 | 0 | 2 | 172 | 0 | 1.4 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 56 | 1 | 2 | 120 | 236 | 0 | 0 | 178 | 0 | 0.8 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 62 | 0 | 4 | 140 | 268 | 0 | 2 | 160 | 0 | 3.6 | 3 | 2.0 | 3.0 | 3 |\n",
       "| 57 | 0 | 4 | 120 | 354 | 0 | 0 | 163 | 1 | 0.6 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 63 | 1 | 4 | 130 | 254 | 0 | 2 | 147 | 0 | 1.4 | 2 | 1.0 | 7.0 | 2 |\n",
       "| 53 | 1 | 4 | 140 | 203 | 1 | 2 | 155 | 1 | 3.1 | 3 | 0.0 | 7.0 | 1 |\n",
       "| 57 | 1 | 4 | 140 | 192 | 0 | 0 | 148 | 0 | 0.4 | 2 | 0.0 | 6.0 | 0 |\n",
       "| 56 | 0 | 2 | 140 | 294 | 0 | 2 | 153 | 0 | 1.3 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 56 | 1 | 3 | 130 | 256 | 1 | 2 | 142 | 1 | 0.6 | 2 | 1.0 | 6.0 | 2 |\n",
       "| 44 | 1 | 2 | 120 | 263 | 0 | 0 | 173 | 0 | 0.0 | 1 | 0.0 | 7.0 | 0 |\n",
       "| 52 | 1 | 3 | 172 | 199 | 1 | 0 | 162 | 0 | 0.5 | 1 | 0.0 | 7.0 | 0 |\n",
       "| 57 | 1 | 3 | 150 | 168 | 0 | 0 | 174 | 0 | 1.6 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 48 | 1 | 2 | 110 | 229 | 0 | 0 | 168 | 0 | 1.0 | 3 | 0.0 | 7.0 | 1 |\n",
       "| 54 | 1 | 4 | 140 | 239 | 0 | 0 | 160 | 0 | 1.2 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 48 | 0 | 3 | 130 | 275 | 0 | 0 | 139 | 0 | 0.2 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 49 | 1 | 2 | 130 | 266 | 0 | 0 | 171 | 0 | 0.6 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 64 | 1 | 1 | 110 | 211 | 0 | 2 | 144 | 1 | 1.8 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 58 | 0 | 1 | 150 | 283 | 1 | 2 | 162 | 0 | 1.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 58 | 1 | 2 | 120 | 284 | 0 | 2 | 160 | 0 | 1.8 | 2 | 0.0 | 3.0 | 1 |\n",
       "| 58 | 1 | 3 | 132 | 224 | 0 | 2 | 173 | 0 | 3.2 | 1 | 2.0 | 7.0 | 3 |\n",
       "| 60 | 1 | 4 | 130 | 206 | 0 | 2 | 132 | 1 | 2.4 | 2 | 2.0 | 7.0 | 4 |\n",
       "| 50 | 0 | 3 | 120 | 219 | 0 | 0 | 158 | 0 | 1.6 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 58 | 0 | 3 | 120 | 340 | 0 | 0 | 172 | 0 | 0.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 66 | 0 | 1 | 150 | 226 | 0 | 0 | 114 | 0 | 2.6 | 3 | 0.0 | 3.0 | 0 |\n",
       "| 43 | 1 | 4 | 150 | 247 | 0 | 0 | 171 | 0 | 1.5 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 40 | 1 | 4 | 110 | 167 | 0 | 2 | 114 | 1 | 2.0 | 2 | 0.0 | 7.0 | 3 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 71 | 0 | 4 | 112 | 149 | 0 | 0 | 125 | 0 | 1.6 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 59 | 1 | 1 | 134 | 204 | 0 | 0 | 162 | 0 | 0.8 | 1 | 2.0 | 3.0 | 1 |\n",
       "| 64 | 1 | 1 | 170 | 227 | 0 | 2 | 155 | 0 | 0.6 | 2 | 0.0 | 7.0 | 0 |\n",
       "| 66 | 0 | 3 | 146 | 278 | 0 | 2 | 152 | 0 | 0.0 | 2 | 1.0 | 3.0 | 0 |\n",
       "| 39 | 0 | 3 | 138 | 220 | 0 | 0 | 152 | 0 | 0.0 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 57 | 1 | 2 | 154 | 232 | 0 | 2 | 164 | 0 | 0.0 | 1 | 1.0 | 3.0 | 1 |\n",
       "| 58 | 0 | 4 | 130 | 197 | 0 | 0 | 131 | 0 | 0.6 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 57 | 1 | 4 | 110 | 335 | 0 | 0 | 143 | 1 | 3.0 | 2 | 1.0 | 7.0 | 2 |\n",
       "| 47 | 1 | 3 | 130 | 253 | 0 | 0 | 179 | 0 | 0.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 55 | 0 | 4 | 128 | 205 | 0 | 1 | 130 | 1 | 2.0 | 2 | 1.0 | 7.0 | 3 |\n",
       "| 35 | 1 | 2 | 122 | 192 | 0 | 0 | 174 | 0 | 0.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 61 | 1 | 4 | 148 | 203 | 0 | 0 | 161 | 0 | 0.0 | 1 | 1.0 | 7.0 | 2 |\n",
       "| 58 | 1 | 4 | 114 | 318 | 0 | 1 | 140 | 0 | 4.4 | 3 | 3.0 | 6.0 | 4 |\n",
       "| 58 | 0 | 4 | 170 | 225 | 1 | 2 | 146 | 1 | 2.8 | 2 | 2.0 | 6.0 | 2 |\n",
       "| 58 | 1 | 2 | 125 | 220 | 0 | 0 | 144 | 0 | 0.4 | 2 | ?   | 7.0 | 0 |\n",
       "| 56 | 1 | 2 | 130 | 221 | 0 | 2 | 163 | 0 | 0.0 | 1 | 0.0 | 7.0 | 0 |\n",
       "| 56 | 1 | 2 | 120 | 240 | 0 | 0 | 169 | 0 | 0.0 | 3 | 0.0 | 3.0 | 0 |\n",
       "| 67 | 1 | 3 | 152 | 212 | 0 | 2 | 150 | 0 | 0.8 | 2 | 0.0 | 7.0 | 1 |\n",
       "| 55 | 0 | 2 | 132 | 342 | 0 | 0 | 166 | 0 | 1.2 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 44 | 1 | 4 | 120 | 169 | 0 | 0 | 144 | 1 | 2.8 | 3 | 0.0 | 6.0 | 2 |\n",
       "| 63 | 1 | 4 | 140 | 187 | 0 | 2 | 144 | 1 | 4.0 | 1 | 2.0 | 7.0 | 2 |\n",
       "| 63 | 0 | 4 | 124 | 197 | 0 | 0 | 136 | 1 | 0.0 | 2 | 0.0 | 3.0 | 1 |\n",
       "| 41 | 1 | 2 | 120 | 157 | 0 | 0 | 182 | 0 | 0.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 59 | 1 | 4 | 164 | 176 | 1 | 2 |  90 | 0 | 1.0 | 2 | 2.0 | 6.0 | 3 |\n",
       "| 57 | 0 | 4 | 140 | 241 | 0 | 0 | 123 | 1 | 0.2 | 2 | 0.0 | 7.0 | 1 |\n",
       "| 45 | 1 | 1 | 110 | 264 | 0 | 0 | 132 | 0 | 1.2 | 2 | 0.0 | 7.0 | 1 |\n",
       "| 68 | 1 | 4 | 144 | 193 | 1 | 0 | 141 | 0 | 3.4 | 2 | 2.0 | 7.0 | 2 |\n",
       "| 57 | 1 | 4 | 130 | 131 | 0 | 0 | 115 | 1 | 1.2 | 2 | 1.0 | 7.0 | 3 |\n",
       "| 57 | 0 | 2 | 130 | 236 | 0 | 2 | 174 | 0 | 0.0 | 2 | 1.0 | 3.0 | 1 |\n",
       "| 38 | 1 | 3 | 138 | 175 | 0 | 0 | 173 | 0 | 0.0 | 1 | ?   | 3.0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "    Age Sex Chest Pain Type Resting blood Pressure Cholesterol\n",
       "1   63  1   1               145                    233        \n",
       "2   67  1   4               160                    286        \n",
       "3   67  1   4               120                    229        \n",
       "4   37  1   3               130                    250        \n",
       "5   41  0   2               130                    204        \n",
       "6   56  1   2               120                    236        \n",
       "7   62  0   4               140                    268        \n",
       "8   57  0   4               120                    354        \n",
       "9   63  1   4               130                    254        \n",
       "10  53  1   4               140                    203        \n",
       "11  57  1   4               140                    192        \n",
       "12  56  0   2               140                    294        \n",
       "13  56  1   3               130                    256        \n",
       "14  44  1   2               120                    263        \n",
       "15  52  1   3               172                    199        \n",
       "16  57  1   3               150                    168        \n",
       "17  48  1   2               110                    229        \n",
       "18  54  1   4               140                    239        \n",
       "19  48  0   3               130                    275        \n",
       "20  49  1   2               130                    266        \n",
       "21  64  1   1               110                    211        \n",
       "22  58  0   1               150                    283        \n",
       "23  58  1   2               120                    284        \n",
       "24  58  1   3               132                    224        \n",
       "25  60  1   4               130                    206        \n",
       "26  50  0   3               120                    219        \n",
       "27  58  0   3               120                    340        \n",
       "28  66  0   1               150                    226        \n",
       "29  43  1   4               150                    247        \n",
       "30  40  1   4               110                    167        \n",
       "⋮   ⋮   ⋮   ⋮               ⋮                      ⋮          \n",
       "274 71  0   4               112                    149        \n",
       "275 59  1   1               134                    204        \n",
       "276 64  1   1               170                    227        \n",
       "277 66  0   3               146                    278        \n",
       "278 39  0   3               138                    220        \n",
       "279 57  1   2               154                    232        \n",
       "280 58  0   4               130                    197        \n",
       "281 57  1   4               110                    335        \n",
       "282 47  1   3               130                    253        \n",
       "283 55  0   4               128                    205        \n",
       "284 35  1   2               122                    192        \n",
       "285 61  1   4               148                    203        \n",
       "286 58  1   4               114                    318        \n",
       "287 58  0   4               170                    225        \n",
       "288 58  1   2               125                    220        \n",
       "289 56  1   2               130                    221        \n",
       "290 56  1   2               120                    240        \n",
       "291 67  1   3               152                    212        \n",
       "292 55  0   2               132                    342        \n",
       "293 44  1   4               120                    169        \n",
       "294 63  1   4               140                    187        \n",
       "295 63  0   4               124                    197        \n",
       "296 41  1   2               120                    157        \n",
       "297 59  1   4               164                    176        \n",
       "298 57  0   4               140                    241        \n",
       "299 45  1   1               110                    264        \n",
       "300 68  1   4               144                    193        \n",
       "301 57  1   4               130                    131        \n",
       "302 57  0   2               130                    236        \n",
       "303 38  1   3               138                    175        \n",
       "    Fasting Blood Sugar Resting ECG Max Heart Rate Excersize Induced Angina\n",
       "1   1                   2           150            0                       \n",
       "2   0                   2           108            1                       \n",
       "3   0                   2           129            1                       \n",
       "4   0                   0           187            0                       \n",
       "5   0                   2           172            0                       \n",
       "6   0                   0           178            0                       \n",
       "7   0                   2           160            0                       \n",
       "8   0                   0           163            1                       \n",
       "9   0                   2           147            0                       \n",
       "10  1                   2           155            1                       \n",
       "11  0                   0           148            0                       \n",
       "12  0                   2           153            0                       \n",
       "13  1                   2           142            1                       \n",
       "14  0                   0           173            0                       \n",
       "15  1                   0           162            0                       \n",
       "16  0                   0           174            0                       \n",
       "17  0                   0           168            0                       \n",
       "18  0                   0           160            0                       \n",
       "19  0                   0           139            0                       \n",
       "20  0                   0           171            0                       \n",
       "21  0                   2           144            1                       \n",
       "22  1                   2           162            0                       \n",
       "23  0                   2           160            0                       \n",
       "24  0                   2           173            0                       \n",
       "25  0                   2           132            1                       \n",
       "26  0                   0           158            0                       \n",
       "27  0                   0           172            0                       \n",
       "28  0                   0           114            0                       \n",
       "29  0                   0           171            0                       \n",
       "30  0                   2           114            1                       \n",
       "⋮   ⋮                   ⋮           ⋮              ⋮                       \n",
       "274 0                   0           125            0                       \n",
       "275 0                   0           162            0                       \n",
       "276 0                   2           155            0                       \n",
       "277 0                   2           152            0                       \n",
       "278 0                   0           152            0                       \n",
       "279 0                   2           164            0                       \n",
       "280 0                   0           131            0                       \n",
       "281 0                   0           143            1                       \n",
       "282 0                   0           179            0                       \n",
       "283 0                   1           130            1                       \n",
       "284 0                   0           174            0                       \n",
       "285 0                   0           161            0                       \n",
       "286 0                   1           140            0                       \n",
       "287 1                   2           146            1                       \n",
       "288 0                   0           144            0                       \n",
       "289 0                   2           163            0                       \n",
       "290 0                   0           169            0                       \n",
       "291 0                   2           150            0                       \n",
       "292 0                   0           166            0                       \n",
       "293 0                   0           144            1                       \n",
       "294 0                   2           144            1                       \n",
       "295 0                   0           136            1                       \n",
       "296 0                   0           182            0                       \n",
       "297 1                   2            90            0                       \n",
       "298 0                   0           123            1                       \n",
       "299 0                   0           132            0                       \n",
       "300 1                   0           141            0                       \n",
       "301 0                   0           115            1                       \n",
       "302 0                   2           174            0                       \n",
       "303 0                   0           173            0                       \n",
       "    ST Depression Slope Number of Major Vessels Thal Heart Disease Diagnosis\n",
       "1   2.3           3     0.0                     6.0  0                      \n",
       "2   1.5           2     3.0                     3.0  2                      \n",
       "3   2.6           2     2.0                     7.0  1                      \n",
       "4   3.5           3     0.0                     3.0  0                      \n",
       "5   1.4           1     0.0                     3.0  0                      \n",
       "6   0.8           1     0.0                     3.0  0                      \n",
       "7   3.6           3     2.0                     3.0  3                      \n",
       "8   0.6           1     0.0                     3.0  0                      \n",
       "9   1.4           2     1.0                     7.0  2                      \n",
       "10  3.1           3     0.0                     7.0  1                      \n",
       "11  0.4           2     0.0                     6.0  0                      \n",
       "12  1.3           2     0.0                     3.0  0                      \n",
       "13  0.6           2     1.0                     6.0  2                      \n",
       "14  0.0           1     0.0                     7.0  0                      \n",
       "15  0.5           1     0.0                     7.0  0                      \n",
       "16  1.6           1     0.0                     3.0  0                      \n",
       "17  1.0           3     0.0                     7.0  1                      \n",
       "18  1.2           1     0.0                     3.0  0                      \n",
       "19  0.2           1     0.0                     3.0  0                      \n",
       "20  0.6           1     0.0                     3.0  0                      \n",
       "21  1.8           2     0.0                     3.0  0                      \n",
       "22  1.0           1     0.0                     3.0  0                      \n",
       "23  1.8           2     0.0                     3.0  1                      \n",
       "24  3.2           1     2.0                     7.0  3                      \n",
       "25  2.4           2     2.0                     7.0  4                      \n",
       "26  1.6           2     0.0                     3.0  0                      \n",
       "27  0.0           1     0.0                     3.0  0                      \n",
       "28  2.6           3     0.0                     3.0  0                      \n",
       "29  1.5           1     0.0                     3.0  0                      \n",
       "30  2.0           2     0.0                     7.0  3                      \n",
       "⋮   ⋮             ⋮     ⋮                       ⋮    ⋮                      \n",
       "274 1.6           2     0.0                     3.0  0                      \n",
       "275 0.8           1     2.0                     3.0  1                      \n",
       "276 0.6           2     0.0                     7.0  0                      \n",
       "277 0.0           2     1.0                     3.0  0                      \n",
       "278 0.0           2     0.0                     3.0  0                      \n",
       "279 0.0           1     1.0                     3.0  1                      \n",
       "280 0.6           2     0.0                     3.0  0                      \n",
       "281 3.0           2     1.0                     7.0  2                      \n",
       "282 0.0           1     0.0                     3.0  0                      \n",
       "283 2.0           2     1.0                     7.0  3                      \n",
       "284 0.0           1     0.0                     3.0  0                      \n",
       "285 0.0           1     1.0                     7.0  2                      \n",
       "286 4.4           3     3.0                     6.0  4                      \n",
       "287 2.8           2     2.0                     6.0  2                      \n",
       "288 0.4           2     ?                       7.0  0                      \n",
       "289 0.0           1     0.0                     7.0  0                      \n",
       "290 0.0           3     0.0                     3.0  0                      \n",
       "291 0.8           2     0.0                     7.0  1                      \n",
       "292 1.2           1     0.0                     3.0  0                      \n",
       "293 2.8           3     0.0                     6.0  2                      \n",
       "294 4.0           1     2.0                     7.0  2                      \n",
       "295 0.0           2     0.0                     3.0  1                      \n",
       "296 0.0           1     0.0                     3.0  0                      \n",
       "297 1.0           2     2.0                     6.0  3                      \n",
       "298 0.2           2     0.0                     7.0  1                      \n",
       "299 1.2           2     0.0                     7.0  1                      \n",
       "300 3.4           2     2.0                     7.0  2                      \n",
       "301 1.2           2     1.0                     7.0  3                      \n",
       "302 0.0           2     1.0                     3.0  1                      \n",
       "303 0.0           1     ?                       3.0  0                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleavland <-read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\", col_names = FALSE)\n",
    "colnames(cleavland) = c(\"Age\", \"Sex\", \"Chest Pain Type\", \"Resting blood Pressure\", \"Cholesterol\", \"Fasting Blood Sugar\",\n",
    "                        \"Resting ECG\", \"Max Heart Rate\", \"Excersize Induced Angina\", \"ST Depression\", \"Slope\",\n",
    "                         \"Number of Major Vessels\", \"Thal\", \"Heart Disease Diagnosis\")\n",
    "cleavland"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
